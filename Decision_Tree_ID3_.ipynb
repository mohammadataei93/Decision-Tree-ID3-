{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Decision Tree ID3 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8dNn1GD3t_U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7n3oMtY3xuM"
      },
      "source": [
        "function to compute the entropy of a leaf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU__W5D03t_X"
      },
      "source": [
        "def entropy(freq):\n",
        "    freq_0 = freq[np.array(freq).nonzero()[0]]\n",
        "    prob_0 = freq_0/float(freq_0.sum())\n",
        "    return -np.sum(prob_0*np.log2(prob_0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVy0mkqz3-Xy"
      },
      "source": [
        "a class that represent each node of the tree\n",
        "\n",
        "every node of the tree will be a instance of this class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C-EOUom3t_Y"
      },
      "source": [
        "class TreeNode(object):\n",
        "    def __init__(self, ids =[], children = [], entropy = 0, depth = 0):\n",
        "        self.ids = ids           \n",
        "        self.entropy = entropy  \n",
        "        self.depth = depth      \n",
        "        self.split_attribute = None \n",
        "        self.children = children \n",
        "        self.order = None     \n",
        "        self.label = None  \n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.split_attribute!=None :return self.split_attribute   \n",
        "        else: return 'leaf'\n",
        "    \n",
        "    def set_properties(self, split_attribute, order):\n",
        "        self.split_attribute = split_attribute\n",
        "        self.order = order\n",
        "\n",
        "    def set_label(self, label):\n",
        "        self.label = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAOsGcXu4ec_"
      },
      "source": [
        "Decision Tree class that have all attributes and functions of the tree \n",
        "\n",
        "with this class we can fit data to make an appropriate tree , evaluate and even prun it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyfVUP2A3t_Z"
      },
      "source": [
        "class DecisionTreeID3(object):\n",
        "    def __init__(self, max_depth= 10):\n",
        "        self.root = None \n",
        "        self.max_depth = max_depth\n",
        "        self.Ntrain = 0 \n",
        "        self.nodes=[] \n",
        "    \n",
        "    def fit(self, data, target, x_val, y_val):\n",
        "        self.Ntrain = data.count()[0]  \n",
        "        self.data = data              \n",
        "        self.attributes = list(data)  \n",
        "        self.target = target         \n",
        "        self.labels = target.unique()\n",
        "        \n",
        "        ids = range(self.Ntrain)\n",
        "        self.root = TreeNode(ids = ids, entropy = self._entropy(ids), depth = 0)  \n",
        "        queue = [self.root]\n",
        "        while queue: \n",
        "            node = queue.pop()\n",
        "\n",
        "            if node.depth < self.max_depth:\n",
        "                node.children = self._split(node)\n",
        "                if not node.children: \n",
        "                    self._set_label(node)\n",
        "                queue += node.children\n",
        "                self.nodes += node.children\n",
        "            else:\n",
        "                self._set_label(node)       \n",
        "        self.acc=self.evaluation(x_val,y_val,True)      \n",
        "                \n",
        "    def _entropy(self, ids):\n",
        "        if len(ids) == 0: return 0\n",
        "        ids=list(ids)\n",
        "        freq = np.array(self.target[ids].value_counts())\n",
        "        return entropy(freq)\n",
        "\n",
        "    def _set_label(self, node):\n",
        "        target_ids =list(node.ids)\n",
        "        node.set_label(self.target[target_ids].mode()[0])\n",
        "\n",
        "    \n",
        "    def _split(self, node):\n",
        "        ids = node.ids \n",
        "        best_gain = 0\n",
        "        best_splits = []\n",
        "        best_attribute = None\n",
        "        order = None\n",
        "        sub_data = self.data.iloc[ids, :]\n",
        "        for i, att in enumerate(self.attributes):\n",
        "            values = self.data.iloc[ids, i].unique().tolist()\n",
        "            if len(values) == 1: continue # entropy = 0\n",
        "            splits = []\n",
        "            for val in values: \n",
        "                sub_ids = sub_data.index[sub_data[att] == val].tolist()\n",
        "                splits.append([sub_id for sub_id in sub_ids])\n",
        "                HxS= 0\n",
        "            for split in splits:\n",
        "                HxS += len(split)*self._entropy(split)/len(ids)\n",
        "            gain = node.entropy - HxS \n",
        "            if gain > best_gain:\n",
        "                best_gain = gain \n",
        "                best_splits = splits\n",
        "                best_attribute = att\n",
        "                order = values\n",
        "        node.set_properties(best_attribute, order)\n",
        "        child_nodes = [TreeNode(ids = split,\n",
        "                     entropy = self._entropy(split), depth = node.depth + 1) for split in best_splits]\n",
        "        return child_nodes\n",
        "\n",
        "    def predict(self, new_data):\n",
        "\n",
        "        npoints = new_data.count()[0]\n",
        "        labels = [None]*npoints\n",
        "        for n in range(npoints):\n",
        "            x = new_data.iloc[n, :] \n",
        "            node = self.root\n",
        "            while node.children: \n",
        "                if x[node.split_attribute] in node.order:\n",
        "                    node = node.children[node.order.index(x[node.split_attribute])]\n",
        "                else:           \n",
        "                    node.label=self._set_label(node)\n",
        "                    break\n",
        "            labels[n] = node.label  \n",
        "        return labels\n",
        "    \n",
        "    def evaluation(self,x_test,y_test,show_acc=False):\n",
        "        z=self.predict(x_test)\n",
        "        count=0\n",
        "        for i in range(len(y_test)):\n",
        "            if y_test[i]==z[i]:\n",
        "                count+=1\n",
        "        if show_acc:\n",
        "            print((count/len(x_test))*100) \n",
        "        self.acc=count/len(x_test)*100\n",
        "        return count/len(x_test)*100\n",
        "    \n",
        "    def _eval(self,x_test,y_test,show_acc=False):\n",
        "        z=self.predict(x_test)\n",
        "        count=0\n",
        "        for i in range(len(y_test)):\n",
        "            if y_test[i]==z[i]:\n",
        "                count+=1\n",
        "        if show_acc:\n",
        "            print((count/len(x_test))*100) \n",
        "        return count/len(x_test)*100    \n",
        "    \n",
        "    \n",
        "    def pruning(self,x2,y2,x_tr,y_tr,x_te,y_te): \n",
        "        max_depth=0\n",
        "        for n in self.nodes:\n",
        "            if n.depth>max_depth:\n",
        "                max_depth=n.depth\n",
        "        prun_list=[]\n",
        "        for n in self.nodes:\n",
        "            if n.children:\n",
        "                prun_list.append(n)\n",
        "        prun_list1=[]\n",
        "        for dep in range(1,max_depth):\n",
        "            for n in prun_list:\n",
        "                if n.depth==dep: prun_list1.append(n)   \n",
        "        before_pr=len(prun_list1)\n",
        "        acc=100\n",
        "        last_acc=self.acc\n",
        "        nodes=[]\n",
        "        val_acc=[]\n",
        "        while acc +.2 >= last_acc: \n",
        "            pr_node=prun_list1.pop()\n",
        "            if pr_node.children:\n",
        "                last_node=pr_node.children\n",
        "                pr_node.children=[]\n",
        "                self._set_label(pr_node)\n",
        "                last_acc=self.acc\n",
        "                acc=self.evaluation(x2,y2,False)\n",
        "                before_pr-=1\n",
        "                nodes.append(before_pr)\n",
        "                print(before_pr)\n",
        "                val_acc.append(self._eval(x2,y2,True))\n",
        "                print('    ')\n",
        "                print('    ')\n",
        "        pr_node.children=last_node        \n",
        "        self.acc=self.evaluation(x2,y2)\n",
        "        \n",
        "        return nodes,val_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdLu3O6o5TAu"
      },
      "source": [
        "some preprocessing for the adult data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN1tYtZr3t_a"
      },
      "source": [
        "def load_data(add):\n",
        "    data=pd.read_csv(add)\n",
        "    data=pd.DataFrame(data)\n",
        "    data=data.replace({'<=50K':0})\n",
        "    data=data.replace({'>50K':1})\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "712XuYAT3t_b"
      },
      "source": [
        "def pre_train(train_data,percentage):\n",
        "    idx=range(len(train_data))\n",
        "    idx=list(idx)\n",
        "    random.shuffle(idx)\n",
        "    aa=int(percentage*len(train_data)/100)\n",
        "    idx=idx[:aa]\n",
        "    x1=train_data.iloc[idx,:]\n",
        "    x1.index=range(aa)\n",
        "    x = x1.iloc[:, 1:]\n",
        "    y = x1.iloc[:, 0] \n",
        "    return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlWaGmHS3t_b"
      },
      "source": [
        "def train_val_split(data,percentage):\n",
        "    idx=range(len(data))\n",
        "    idx=list(idx)\n",
        "    random.shuffle(idx)\n",
        "    aa=int(percentage*len(data)/100)\n",
        "    idx1=idx[:aa]\n",
        "    idx2=idx[aa:]\n",
        "    x_tr=data.iloc[idx1,:]\n",
        "    x_val=data.iloc[idx2,:]\n",
        "    x_tr.index=range(aa)\n",
        "    x_val.index=range(len(data)-aa)\n",
        "    x_tr_ = x_tr.iloc[:, 1:]\n",
        "    y_tr_ = x_tr.iloc[:, 0] \n",
        "    x_val_ = x_val.iloc[:, 1:]\n",
        "    y_val_= x_val.iloc[:, 0] \n",
        "    \n",
        "    return x_tr_,y_tr_,x_val_,y_val_   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUZkVm3B3t_c"
      },
      "source": [
        "data=load_data('C:/Users/NP-soft/Desktop/data/Decision Tree ID3/adult.train.csv')\n",
        "x1,y1,x2,y2=train_val_split(data,80)\n",
        "x1,y1=pre_train(data,100)\n",
        "test_data=load_data('C:/Users/NP-soft/Desktop/data/Decision Tree ID3/adult.test.csv')\n",
        "x2,y2,x_test,y_test=train_val_split(test_data,25)\n",
        "x_test = test_data.iloc[:, 1:]\n",
        "y_test= test_data.iloc[:, 0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59jE4bRF5Z_o"
      },
      "source": [
        "make a instance of DecisionTreeID3 class , fit the adult data to it and show the evlauation and test accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tr8tg7T3t_c",
        "outputId": "897a6e3c-2660-42ac-c448-4363324b58e9"
      },
      "source": [
        "tree = DecisionTreeID3(max_depth = 7)\n",
        "tree.fit(x1,y1,x2,y2)\n",
        "tree.evaluation(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}